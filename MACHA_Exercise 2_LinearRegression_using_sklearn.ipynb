"""
Created on Sat Mar 29 23:04:37 2025

@author: MSCS_Macha Maritess
"""
import pandas as pandas_library
import numpy as numpy_library
import statsmodels.api as statistics_models
import matplotlib.pyplot as plotting_library
import seaborn as seaborn_library
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import os

# Load dataset
file_path = r"C:\Users\MSCS_\Downloads\dataset\supermarket_sales.csv"  # Ensure correct file path

def check_file_existence(file_path):
    if not os.path.exists(file_path):
        print("Available files in directory:", os.listdir(os.path.dirname(file_path)))
        raise FileNotFoundError(f"Dataset file not found: {file_path}. Please check the file path.")

check_file_existence(file_path)

try:
    dataframe = pandas_library.read_csv(file_path, encoding="utf-8")
except UnicodeDecodeError:
    dataframe = pandas_library.read_csv(file_path, encoding="latin1")
except FileNotFoundError:
    raise FileNotFoundError(f"Dataset file not found: {file_path}. Please check the file path.")

# Display basic information
print(dataframe.info())
print(dataframe.describe())

# Ensure required columns exist
essential_columns = ['Gender', 'Product line', 'Total', 'Rating']
for column in essential_columns:
    if column not in dataframe.columns:
        raise ValueError(f"Missing required column: {column}")

# Convert categorical variables to numeric
dataframe = pandas_library.get_dummies(dataframe, drop_first=True)

# Explicitly convert numeric columns
dataframe_numeric = dataframe.select_dtypes(include=[numpy_library.number])
dataframe[dataframe_numeric.columns] = dataframe_numeric.apply(pandas_library.to_numeric, errors='coerce')

# Drop rows with NaN values
dataframe.dropna(inplace=True)

# Ensure dataset is not empty
if dataframe.empty:
    raise ValueError("Dataset is empty after preprocessing. Check for missing or invalid values.")

# Step 1: Correlation Analysis
target_variable = "Total"
if target_variable not in dataframe.columns:
    raise ValueError("Target variable not found in dataset")

correlation_matrix = dataframe.corr(numeric_only=True)
correlation_target = correlation_matrix[target_variable].dropna().sort_values(ascending=False)

# Select the highest correlated independent variable (excluding target itself)
if len(correlation_target) > 1:
    independent_variable_univariate = correlation_target.index[1]
else:
    raise ValueError("No suitable independent variable found for univariate regression.")

# Step 2: Univariate Regression
X_univariate = dataframe[[independent_variable_univariate]]
y_target = dataframe[target_variable]
X_univariate_train, X_univariate_test, y_train, y_test = train_test_split(X_univariate, y_target, test_size=0.2, random_state=42)

univariate_model = LinearRegression()
univariate_model.fit(X_univariate_train, y_train)
y_univariate_predicted = univariate_model.predict(X_univariate_test)

r_squared_univariate = round(univariate_model.score(X_univariate_test, y_test), 4)
mean_squared_error_univariate = round(mean_squared_error(y_test, y_univariate_predicted), 4)
root_mean_squared_error_univariate = round(numpy_library.sqrt(mean_squared_error_univariate), 4)

# Step 3: Multivariate Regression (Select variables with p-value = 0.000)
X_independent_variables = dataframe.drop(columns=[target_variable])
X_with_constant = statistics_models.add_constant(X_independent_variables, has_constant='add')

# Ensure all columns are numeric before fitting the model
X_with_constant = X_with_constant.select_dtypes(include=[numpy_library.number])

# Fit the model
model = statistics_models.OLS(y_target, X_with_constant).fit()

significant_variables = model.pvalues[model.pvalues == 0.000].index.tolist()
if 'const' in significant_variables:
    significant_variables.remove('const')

if not significant_variables:
    raise ValueError("No independent variables found with p-value = 0.000")

X_multivariate = dataframe[significant_variables]
X_multivariate_train, X_multivariate_test, y_train, y_test = train_test_split(X_multivariate, y_target, test_size=0.2, random_state=42)

multivariate_model = LinearRegression()
multivariate_model.fit(X_multivariate_train, y_train)
y_multivariate_predicted = multivariate_model.predict(X_multivariate_test)

r_squared_multivariate = round(multivariate_model.score(X_multivariate_test, y_test), 4)
mean_squared_error_multivariate = round(mean_squared_error(y_test, y_multivariate_predicted), 4)
root_mean_squared_error_multivariate = round(numpy_library.sqrt(mean_squared_error_multivariate), 4)

# Print results
print(f"Univariate Regression: R²={r_squared_univariate}, MSE={mean_squared_error_univariate}, RMSE={root_mean_squared_error_univariate}")
print(f"Multivariate Regression: R²={r_squared_multivariate}, MSE={mean_squared_error_multivariate}, RMSE={root_mean_squared_error_multivariate}")

# Create a DataFrame to compare results
comparison_table = pandas_library.DataFrame({
    "Model": ["Univariate Regression", "Multivariate Regression"],
    "R² Score": [r_squared_univariate, r_squared_multivariate],
    "Mean Squared Error (MSE)": [mean_squared_error_univariate, mean_squared_error_multivariate],
    "Root Mean Squared Error (RMSE)": [root_mean_squared_error_univariate, root_mean_squared_error_multivariate]
})

# Display the comparison
print(comparison_table)

# Visualization
plotting_library.figure(figsize=(10, 5))
plotting_library.scatter(y_test, y_univariate_predicted, label="Univariate Predictions", alpha=0.6)
plotting_library.scatter(y_test, y_multivariate_predicted, label="Multivariate Predictions", alpha=0.6)
plotting_library.plot(y_test, y_test, color='red', linestyle='dashed', label="Ideal Fit")
plotting_library.xlabel("Actual Values")
plotting_library.ylabel("Predicted Values")
plotting_library.title("Actual vs Predicted Values")
plotting_library.legend()
plotting_library.show()
